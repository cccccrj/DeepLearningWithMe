# DeepLearningWithMe
#《**跟我一起深度学习**》

## 第一部分：前馈神经网络

- [你告诉我什么是深度学习](http://mp.weixin.qq.com/s?__biz=MzAwNjU0NjA3Ng==&mid=2247485889&idx=1&sn=306ad5015af4a60aad29cd48338afee6&chksm=9b0afe32ac7d77243a3b7e4dda7a49646018c5f33cd9e7d4cdcc6da76d04d4a5153df29d6498#rd)
- [这样拟合正弦函数你会吗？](http://mp.weixin.qq.com/s?__biz=MzAwNjU0NjA3Ng==&mid=2247486265&idx=1&sn=b3974aa3653a0e26de0b12c94f183962&chksm=9b0afccaac7d75dc33c80f29fcc11cd512ec95bd4ad9a8ac773926f3dd77dc65126999b297e5#rd)
- [Pytorch之Linear与MSELoss](http://mp.weixin.qq.com/s?__biz=MzAwNjU0NjA3Ng==&mid=2247486285&idx=1&sn=95c02f690724bd9cb763c3ed14329434&chksm=9b0afcbeac7d75a813fa87d9137fefbdfb87ab9d98732db63b35f657f9b54527df5eff0691b7#rd)
- [想明白多分类必须得谈逻辑回归](http://mp.weixin.qq.com/s?__biz=MzAwNjU0NjA3Ng==&mid=2247486341&idx=1&sn=d6b66a076de0e91b0a353baa649ad4a1&chksm=9b0afc76ac7d7560c2d7a4c696d5d22ea52ef4d1b42ef821177ce2d71619270d16dd4c0e88fa#rd)
- [Pytorch之Softmax多分类任务](http://mp.weixin.qq.com/s?__biz=MzAwNjU0NjA3Ng==&mid=2247486364&idx=1&sn=5f1a24c295aa343b1d46f2854072d2cd&chksm=9b0afc6fac7d7579d6e8b3f354eb0de701b5b0f781f9d939b36366a9ccf5c5cb2934ec235fa9#rd)
- [如何用逻辑回归来完成多分类？](http://mp.weixin.qq.com/s?__biz=MzAwNjU0NjA3Ng==&mid=2247486364&idx=2&sn=fdf4be921ee8e0f636d66eb6e2876ba0&chksm=9b0afc6fac7d75790784b8eafa57127110bd951b895a73c03817088331148dbe0f8d04dceced#rd)
- [Pytorch之简洁实现Softmax多分类](http://mp.weixin.qq.com/s?__biz=MzAwNjU0NjA3Ng==&mid=2247486399&idx=1&sn=42bb7e006f44d514bcc068cafcbc7016&chksm=9b0afc4cac7d755a35259de3b042429b76d3f57c9d7b81432669cac60d9606131ac6cc2a7c37#rd)
- [我告诉你什么是深度学习](http://mp.weixin.qq.com/s?__biz=MzAwNjU0NjA3Ng==&mid=2247486452&idx=1&sn=afd7aaffbef99c7e1bcf9bde6ca996f0&chksm=9b0afc07ac7d7511e5616c54f48615c2e2af5a51b8646f7cf5754da1153c4f1db0e0d7a95183#rd)
- [Pytorch之多层感知机分类任务](http://mp.weixin.qq.com/s?__biz=MzAwNjU0NjA3Ng==&mid=2247486523&idx=1&sn=08e6331babeac1d92c76ecd69344f4b0&chksm=9b0afbc8ac7d72ded1c43830e490aa43ee771546771a6d6cbf0359913870ef05ac1aa983fed4#rd)
- [`l.backward`你到底是个什么东西？](http://mp.weixin.qq.com/s?__biz=MzAwNjU0NjA3Ng==&mid=2247486752&idx=1&sn=1108940e88d819c8a07e89ad2a663852&chksm=9b0afad3ac7d73c57821dba6fec025fd03143679b3047b25979792a8e8b73dbabe0c63805ab7#rd)
- [你还不会实现反向传播?](http://mp.weixin.qq.com/s?__biz=MzAwNjU0NjA3Ng==&mid=2247487278&idx=1&sn=e591059089afa4959ea2346e066f96aa&chksm=9b0af8ddac7d71cbbd06c6908ea5dfc5431be9b81176dcb4edcfb94c59d7feb3df16fd0d0bef#rd)
- [Softmax+Cross entropy 梯度检验](http://mp.weixin.qq.com/s?__biz=MzAwNjU0NjA3Ng==&mid=2247487492&idx=2&sn=74a932e671f6b2f3de6dd670b5b8d567&chksm=9b0ae7f7ac7d6ee114b67914c11def89b2dfadaf32d6f8014a129b4f75e1b15cbeb08fad32ec#rd)

## 第二部分：卷积神经网络

- [看不懂卷积或许只是因为](http://mp.weixin.qq.com/s?__biz=MzAwNjU0NjA3Ng==&mid=2247487744&idx=1&sn=d00de73c71264e0bada8454217f84126&chksm=9b0ae6f3ac7d6fe516ab836e3ee593bfe0786cf3979282a2c8f469b05d6101985b20ec8f577a#rd)
- [原来卷积是这么计算的](http://mp.weixin.qq.com/s?__biz=MzAwNjU0NjA3Ng==&mid=2247487828&idx=1&sn=9daa48ad9ade1ea3f66899cfa9da6a9f&chksm=9b0ae6a7ac7d6fb18c87a2fc869746f695553714b6f75647d53ae5ef791c66019ab67ce93550#rd)
- [卷积操作中的填充与池化](http://mp.weixin.qq.com/s?__biz=MzAwNjU0NjA3Ng==&mid=2247487902&idx=1&sn=15e1cef1ce15157f319b5d49de487097&chksm=9b0ae66dac7d6f7b7a2f53ed96258d98b0fd7dc842a177db2554b041d9f84f4761a36f29eb7d#rd)
- [卷积池化与LeNet5网络模型](https://mp.weixin.qq.com/s/bFO1eaCCMERyvu4QSGyeaQ)
- [LeNet5的继任者AlexNet模型](https://mp.weixin.qq.com/s/ckm_P7T219k8UGUVsI88OA)
- [VGG一个可使用重复元素的网络](https://mp.weixin.qq.com/s/X7VDKcWTRdPvbOZ1Oz7TkQ)
- [NiN一个即使放到现在也不会过时的网络](https://mp.weixin.qq.com/s/dA1AATIrFMTjMk8FYGPqPw)
- [厉害了！能把多尺度卷积说得这么高大上](https://mp.weixin.qq.com/s/3Z-_f4p73V20HEpEHsendA)
- [你看这个网络它又宽又长](https://mp.weixin.qq.com/s/OWINukstH87Yldl99_gItw)
- [不得不说的Batch Normalization](https://mp.weixin.qq.com/s/rqnKx-3F6YycfOVfN5JPlQ)
- [Batch Normalization分析与实现](https://mp.weixin.qq.com/s/0vH7E2zw0vzr8J1bcNLbkA)

## 第三部分：循环神经网络

## 第四部分：模型持久化与迁移运用

## 第五部分： Transformer网络模型
- [This post is all you need（①多头注意力机制原理）](https://mp.weixin.qq.com/s/xBHyOGHWytgAbpKbwP45Nw)
- [This post is all you need（②位置编码与编码解码过程）](https://mp.weixin.qq.com/s/AVU_rxYsPpS-BapBnShenA)

